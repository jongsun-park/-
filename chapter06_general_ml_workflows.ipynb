{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6장 일반적인 머신 러닝 워크플로우\n",
    "\n",
    "머신 러닝의 일반적인 워크플로\n",
    "1. 작업 정의\n",
    "  - 문제 영역과 고객의 이면에 있는 비즈니스 로직을 이해\n",
    "  - 데이터 수집, 데이터 이해, 작업의 성공을 측정하는 방법을 선택\n",
    "2. 모델 개발\n",
    "  - 머신 러닝 모델로 처리할 수 있는 데이터를 준비\n",
    "  - 모델 평가 방법과 기준점 선택\n",
    "  - 일반화 성능을 가지며 과대적합할 수 있는 모델 훈련\n",
    "  - 최대의 일반화 성능에 도달할 때까지 모델에 규제를 추가\n",
    "3. 모델 배포\n",
    "  - 모델을 웹 서버, 모바일 웹, 웹 페이지 또는 임베디드 장치에 배포\n",
    "  - 실전에서 모델의 성능을 모니터링\n",
    "  - 차세대 모델을 구축하기 위한 데이터 수집을 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 작업 정의\n",
    "\n",
    "### 6.1.1 문제 정의\n",
    "\n",
    "우선 순위 질문\n",
    "- 가용 데이터 유무 (많은 경우 새로운 데이터를 수집하고 레이블을 부여해야 한다)\n",
    "- 당면한 문제의 종류 (머신 러닝이 아니라 통계 분석과 같은 다른 방법을 사용해야 할 수도 있다.)\n",
    "  - 이진 분류\n",
    "  - 다중 분류\n",
    "  - 스칼라 회귀\n",
    "  - 벡터 회귀\n",
    "  - 다중 레이블 다중 분류\n",
    "  - 이미지 분할\n",
    "  - 군집\n",
    "  - 생성 \n",
    "  - 강화 학습\n",
    "- 기존 솔루션 (어떤 시스템으로 어떻게 일하고 있는지 이해해야 한다)\n",
    "- 고려해야 할 특별한 제약 (작업이 충족시켜야 할 조건을 완벽하게 이해)\n",
    "\n",
    "초기 단계에서의 가설\n",
    "- 주어진 입력으로 타깃을 예측할 수 있다고 가정한다.\n",
    "- 가용한 데이터(또는 수집할 데이터)에 입력과 출력 사이의 관계를 학습하는 데 충분한 정보가 있다고 가정한다.\n",
    "\n",
    "### 6.1.2 데이터 수집\n",
    "\n",
    "머신러닝 프로젝트에서 가장 힘들고 시간이 많이 걸리며 비용이 많이 드는 단계\n",
    "\n",
    "#### 데이터 애너테이션 인프라에 투자하기\n",
    "\n",
    "#### 대표성 없는 데이터 주의하기\n",
    "\n",
    "(가능하다면) 모델이 사용될 환경에서 직접 데이터를 수집\n",
    "\n",
    "개념 이동(concept drift)\n",
    "- 제품 환경에서 데이터의 속성이 시간에 따라 변할 때 일어난다.\n",
    "- 이로 인해 모델 정확도가 점진적으로 감소된다.\n",
    "- 빠르게 변하는 개념 이동에 대처하려면 지속적인 데이터 수집, 애너테이션, 모델 재훈련이 필요하다. \n",
    "\n",
    "샘플링 편향\n",
    "- 데이터 수집 과정이 예측 대상과 상호 작용하여 편향된 측정 결과를 만들 때 일어난다.\n",
    "\n",
    "### 6.1.3 데이터 이해\n",
    "\n",
    "모델을 훈련을 시작하기 전에 데이터를 탐색하고 시각화하여 예측 능력을 가진 특성에 대한 통찰을 얻어야 한다.\n",
    "\n",
    "타깃 누출(target leaking)\n",
    "- 데이터에 타깃에 관한 정보를 제공하는 특성이 있는지 확인\n",
    "- 데이터에 있는 모든 특성이 제품 환경에도 동일한 형태로 제공될 수 있는지 확인\n",
    "- 예. 암 치료를 받을지 예측하는 모델에서 암 진단을 받았다는 특성이 있는 경우\n",
    "\n",
    "### 6.1.4 성공 지표 선택\n",
    "\n",
    "성공의 지표가 프로젝트 전반에 걸쳐 내리는 기술적 선택을 결정하게 된다.\n",
    "\n",
    "클래스 분포가 균일한 분류 문제\n",
    "- 정확도\n",
    "- ROC 곡선 아래 면적인 ROC AUC\n",
    "\n",
    "클래스 분포가 균등하지 않은 문제, 랭킹 문제, 다중 레이블 분제\n",
    "- 정밀도\n",
    "- 재현율\n",
    "- 정확도\n",
    "- ROC AUC의 가중 평균\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 모델 개발\n",
    "\n",
    "대부분의 튜토리얼과 연구 프로젝트는 \"모델 개발\" 단계만 수행한다.\n",
    "\n",
    "문제 정의, 데이터 수집 -> **모델 개발** -> 모델 배포 및 유지 관리\n",
    "\n",
    "### 6.2.1 데이터 준비\n",
    "\n",
    "데이터 전처리\n",
    "- 주어진 원본 데이터를 신경망에 적용하기 쉽도록 만드는 것\n",
    "- 예. 벡터화, 정규화, 누락된 값 다루기 등\n",
    "- 전처리 기법은 도메인에 특화되어 있다.\n",
    "\n",
    "#### 벡터화\n",
    "\n",
    "신경망에서는 모든 입력과 출력은 일반적으로 부동 소수점(혹은 정수, 문자열)로 이루어진 텐서여야 한다.\n",
    "\n",
    "처리해야 하는 것을 텐서로 변환하는 것을 데이터 벡터화(data vectorization)라고 한다.\n",
    "\n",
    "#### 값 정규화\n",
    "\n",
    "(큰 값) 데이터를 네트워크에 주입하기 전에 0-1 사이의 부동 소수점 값으로 전환한다.\n",
    "\n",
    "(균일하지 않은 데이터) 데이터를 네트워크에 주입하기 전에 각 특성을 독립적으로 정규화하여 평균이 0이고 표준 편차가 1이 되도록 만든다.\n",
    "\n",
    "큰 값과 균일 하지 않은 데이터를 신경망에 바로 주입하는 것은 위험하다. 업데이트할 그레이디언트가 커져 네트워크가 수렴하는 것을 방해한다.\n",
    "\n",
    "네트워크를 쉽게 학습시키도록 데이터는\n",
    "1. 작은 값을 취해야 한다. (0-1)\n",
    "2. 균일해야 한다. (모든 특성이 대체로 비슷한 범위를 가져야 한다)\n",
    "\n",
    "엄격하게 정규화를 한다면\n",
    "1. 각 특성별로 평균이 0이 되도록 정규화\n",
    "2. 각 특성별로 표준편차가 1이 되도록 정규화\n",
    "\n",
    "넘파일 배열에서 정규화\n",
    "\n",
    "```py\n",
    "x -= x.mean(axis=0) # x가 (샘플, 특성) 크기인 2D 행렬이라고 가정\n",
    "x /= x.std(axis=0)\n",
    "```\n",
    "\n",
    "#### 누락된 값 처리하기\n",
    "\n",
    "훈련 데이터에는 누락된 값이 포함될 수 있다.\n",
    "\n",
    "삭제 할 수도 있지만\n",
    "- 범주형 특성: 누락된 값이라는 의미의 새로운 범주를 만드는 것이 안전하다.\n",
    "- 수치형 특성: 누락된 값을 임의의 값(0) 대신 해당 특성의 평균이나 중간 값으로 대체하거나, 다른 특성 값에서 누락된 값을 예측하는 모델을 훈련할 수도 있다.\n",
    "\n",
    "### 6.2.2 평가 방법 선택\n",
    "\n",
    "검증 지표를 통해 모델의 일반화 성능을 측정(신뢰성)\n",
    "\n",
    "세가지 평가 방법\n",
    "- 홀드아웃 검증: 데이터가 풍부할 때.\n",
    "- K-겹 교차 검증: 데이터가 적을 때.\n",
    "- 반복 K-겹 교차 검증: 데이터가 적고 매우 정확한 모델 평가가 필요할 때.\n",
    "\n",
    "주의사항\n",
    "- 검승 세트의 대표성 유의\n",
    "- 훈련 세트와 검증 세트 간 중복된 샘플이 없도록 주의\n",
    "\n",
    "### 6.2.3 기준 모델 뛰어넘기\n",
    "\n",
    "초기 목표\n",
    "- 통계적 검정력(statistical power)을 달성하는 것\n",
    "- 간단한 기준점을 넘을 수 있는 모델을 개발\n",
    "\n",
    "중점\n",
    "- 특성 공학: 유용하지 않은 특성을 제외하고, 문제에 대한 지식을 사용하여 유용할 것 같은 특성을 개발\n",
    "- 구조에 대한 올바른 가정: 어떤 모델을 사용할지, 신경망 자체가 필요한지, 다른 방법은 없는지\n",
    "- 좋은 훈련 옵션 선택: 손실 함수, 배치 크기, 학습률 등\n",
    "\n",
    "올바른 손실 함수 사용하기\n",
    "- 손실 함수는 미니 배치 데이터에서 계산 가능하고 미분 가능해야 한다.\n",
    "- ROC AUC는 직접 최적화 할 수 없기 때문에 크로스엔트로피처럼 ROC AUC를 대신할 지표를 최적화한다. \n",
    "- 크로스엔트로피가 낮을 수록 ROC AUC가 높다고 기대할 수 있다. \n",
    "\n",
    "모델에 맞는 마지막 층의 활성화 함수와 손실 함수 선택\n",
    "| 문제 유형 | 마지막 층의 활성화 함수 | 손실 함수 |\n",
    "| -- | -- | -- |\n",
    "| 이진 분류 | sigmoid | binary_crossentropy |\n",
    "| 단일 레이블 다중 분류 | softmax | categorical_crossentropy |\n",
    "| 다중 레이블 다중 분류 | sigmoid | binary_crossentropy |\n",
    "\n",
    "주어진 작업에 잘 맞는 특성 공학 기법과 모델 구조를 찾기 위해 선행 기술을 조사해야 한다. \n",
    "\n",
    "간단한 기준점을 넘어서지 못한다면, 입력 데이터에 존재하지 않는 것을 얻으려고 한다는 신호일 수 있다.\n",
    "\n",
    "가설\n",
    "- 주어진 입력으로 타깃을 예측할 수 있다고 가정한다.\n",
    "- 가용한 데이터에 입력과 출력 사이의 관계를 학습하는 데 충분한 정보가 있다고 가정한다.\n",
    "\n",
    "가설이 잘못되었다면 처음으로 돌아가야 한다.\n",
    "\n",
    "### 6.2.4 모델 용량 키우기: 과대적합 모델 만들기\n",
    "\n",
    "모델이 충분한 성능을 내는지 평가\n",
    "- 주어진 문제를 모델링하기에 충분한 층과 파라미터가 있는지\n",
    "\n",
    "과소적합과 과대적합의 경계점을 알기 위해서는 우선 \"과대적합\"된 모델을 만들어야 한다.\n",
    "1. 층 추가\n",
    "2. 층 크기 키우기\n",
    "3. 더 많은 에포크 동안 훈련\n",
    "\n",
    "검증 데이터에서 모델 성능이 감소하기 시작했을 때 과대적합에 도달한 것이다. (검증 손실)\n",
    "\n",
    "### 6.2.5 모델 규제와 하이퍼파라미터 튜닝\n",
    "\n",
    "일반화 성능을 최대화하는 것\n",
    "\n",
    "반복적으로 모델을 수정, 훈련, 검증 데이터 평가\n",
    "- 다른 구조 시도 (층 추가, 제거)\n",
    "- 드롭아웃 추가\n",
    "- L1, L2 규제 추가\n",
    "- 하이퍼파라미터 튜닝 (층의 유닛 개수, 옵티마이저의 학습률 등)\n",
    "- 데이터 큐레이션, 특성 공학 시도\n",
    "\n",
    "자동화된 하이퍼파라미터 튜닝 소프트웨어 (예. 케라스 튜너)를 사용하여 작업의 많은 부분을 자동화 할 수 있다.\n",
    "\n",
    "검증 과정에서 얻은 피드백을 바탕으로 모델을 다시 튜닝을 하게 되면 결국 검증 과정에 과대적합 될 수 있다. \n",
    "\n",
    "만족할 만한 설정 값(하이퍼파라미터 튜닝...)을 얻으면 최종적으로 모델을 만들고, 테스트 세트에서 평가한다. \n",
    "\n",
    "테스트 세트 << 검증 세트: 검증 과정에 신뢰성이 없거나 검증 데이터에 과대적합된 것이다. 이런 경우 더 신뢰할 평가 방법으로 바꾸는 것이 좋다. (ex. 반복 K-겹 교차 검증)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 모델 배포\n",
    "\n",
    "### 6.3.1 고객에게 작업 설명하고 기대치 설정하기\n",
    "\n",
    "### 6.3.2 추론 모델 배치하기\n",
    "\n",
    "#### REST API로 모델 배포하기\n",
    "\n",
    "#### 장치로 모델 배포하기\n",
    "\n",
    "#### 브라우저에 모델 배포하기\n",
    "\n",
    "#### 추론 모델 최적화\n",
    "\n",
    "### 6.3.3 작동 중 모델 모니터링 하기\n",
    "\n",
    "### 6.3.4 모델 유지 관리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 요약\n",
    "\n",
    "문제 정의\n",
    "- 넓은 맥락에서 일 이해 (최종 목표, 제약 사항...)\n",
    "- 데이터셋 수집 (데이터 이해)\n",
    "- 성공 측정 방법 (검증 데이터에서 모니터링할 지표)\n",
    "\n",
    "모델 개발\n",
    "- 데이터 준비\n",
    "- 평가 방법 선택 (홀드아웃 검증, K-겹 교차 검증, 검증 데이터 세트 비중)\n",
    "- 통계적 검정력 (간단한 기준점)\n",
    "- 용량 늘이기 (과대적합할 수 있는 모델)\n",
    "- 규제 적용 및 하이퍼파라미터 튜닝\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
